{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Языковые модели. Предсказание следующего слова\n",
    "\n",
    "Одной из задач обработки текстов на естественном языке выступает задача предсказания\n",
    "следующего слова по предшествующим. Примерами таких задач являются задача\n",
    "предсказания следующего слова при наборе текста в смартфоне или дополнение поисковых\n",
    "запросов.\n",
    "\n",
    "## 01.1. Предсказание по предыдущему слову\n",
    "\n",
    "Данная задача может быть сведена к оценке *вероятностей встретить* каждое из возможных\n",
    "слов после имеющегося. Соответствующая языковая модель примет вид:\n",
    "\n",
    "$$\\large w^{*} = \\underset{w_k \\in V}{\\operatorname{argmax}} \\mathbb{P}\\left[w_k | w_{k-1}\\right] \\qquad (1)$$\n",
    "\n",
    "где условная вероятность высчитывается по формуле Байеса:\n",
    "\n",
    "$$\\large \\mathbb{P}\\left[w_k | w_{k-1}\\right]= \\frac{\\mathbb{P}\\left[w_k\\right] \\cdot \\mathbb{P}\\left[w_{k-1} | w_k\\right]}{\\mathbb{P}\\left[w_{k-1}\\right]} \\qquad (2)$$\n",
    "\n",
    "где\n",
    "\n",
    "- $V$ - множество всех возможных слов\n",
    "- $\\mathbb{P}\\left[w_{k} | w_{k-1}\\right]$ - вероятность встретить слово $w_k$ после $w_{k-1}$\n",
    "\n",
    "Для удобства полученную модель можно логарифмировать и представить в следующем виде:\n",
    "\n",
    "$$\\large w^{*} = \\underset{w_k \\in V}{\\operatorname{argmax}} \\left[\\log \\mathbb{P} \\left[w_k \\right] + \\mathbb{P}\\left[w_{k-1} | w_{k}\\right]\\right] \\qquad (3)$$\n",
    "\n",
    "Условные вероятности в формуле $(3)$ могут быть оценен непосредственно по имеющемуся словарю слов. Для этого необходимо рассмотреть имеющиеся в словаре *биграммы*, тогда:\n",
    "\n",
    "$$\\large \\mathbb{P}\\left[w_{k-1} | w_{k}\\right] = \\frac{\\nu_{(w_{k-1}, w_k)}}{\\sum\\limits_{(w_i, w_j) \\in V} \\nu_{(w_i, w_j)}} \\qquad (4)$$\n",
    "\n",
    "где $\\nu_{(w_{k-1}, w_k)}$ - частота встречаемости словосочетания $(w_{k-1}, w_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.2. Предсказание по $m$ последних слов\n",
    "\n",
    "Иногда по последнему слову оказывается невозможным определить следующее, поскольку в нём не учитывается контекст. Например, если последнее слово является союзом, то приемлемые варианты следующего слова определяет и предшествующее данному союзу слово. Оценка вероятности в данном случае проводится на основе $m$ последних слов. \n",
    "\n",
    "Таким образом, модель $(1) - (2)$ принимает вид:\n",
    "\n",
    "$$\\large w^{*} = \\underset{w_k \\in V}{\\operatorname{argmax}} \\mathbb{P}\\left[w_k | w_{k-1}, w_{k-2}, \\ldots, w_{k-m}\\right] \\qquad (5)$$\n",
    "\n",
    "где условная вероятность высчитывается по формуле Байеса:\n",
    "\n",
    "$$\\large \\mathbb{P}\\left[w_k | w_{k-1}, w_{k-2}, \\ldots, w_{k-m}\\right]= \\frac{\\mathbb{P}\\left[w_k\\right] \\cdot \\mathbb{P}\\left[w_{k-1}, w_{k-2}, \\ldots, w_{k-m} | w_k\\right]}{\\mathbb{P}\\left[w_{k-1}, w_{k-2}, \\ldots, w_{k-m}\\right]} \\qquad (6)$$\n",
    "\n",
    "### 01.2.1 Независимость от порядка слов\n",
    "\n",
    "Предположим, что текущее слово $w_k$ зависит только то того, какие слова встретились перед ним и не зависит от того, в каком порядке они встретились. Тогда:\n",
    "\n",
    "$$\\large w^{*} = \\underset{w_k \\in V}{\\operatorname{argmax}} \\mathbb{P}\\left[w_k\\right] \\cdot \\prod\\limits_{i=1}^m \\mathbb{P}\\left[w_{k-i} | w_k \\right] = \\underset{w_k \\in V}{\\operatorname{argmax}} \\left[\\log \\mathbb{P}\\left[w_k\\right] + \\sum\\limits_{i=1}^m \\log \\mathbb{P}\\left[w_{k-i} | w_k \\right]\\right]\\qquad (7)$$\n",
    "\n",
    "где $\\mathbb{P}\\left[w_{k-i} | w_k \\right]$ вычисляются по формуле $(4)$\n",
    "\n",
    "### 01.2.2. Учёт порядка предшествующих слов\n",
    "\n",
    "Языковая модель $(7)$ не учитывает порядок предшествующих слов. Информацию о порядке слов можно добавить путём оценки расстояния до каждого из предшествующих слов. Например, в предложении \"Счастье есть удовольствие без раскаяния\" расстояние между словами \"счастье\" и \"раскаяния\" равно $4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aptmess/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aptmess/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aptmess/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "# Corus - NLP datasets\n",
    "import corus\n",
    "from corus import load_lenta\n",
    "\n",
    "#NLTK - Natural Language Tool Kit\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import bigrams\n",
    "from nltk import ngrams\n",
    "\n",
    "#Other\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся открытыми датасетами из библиотеки `corus`. Для примера, обучимся на новостях `lenta.ru`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<th>Dataset</th>\n",
       "<th>API <code>from corus import</code></th>\n",
       "<th>Tags</th>\n",
       "<th>Texts</th>\n",
       "<th>Uncompressed</th>\n",
       "<th>Description</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://github.com/yutkin/Lenta.Ru-News-Dataset\">Lenta.ru</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_lenta\"></a>\n",
       "<code><a href=\"#load_lenta\">load_lenta</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "739&nbsp;351\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1.66 Gb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://russe.nlpub.org/downloads/\">Lib.rus.ec</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_librusec\"></a>\n",
       "<code><a href=\"#load_librusec\">load_librusec</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>fiction</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "301&nbsp;871\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "144.92 Gb\n",
       "</td>\n",
       "<td>\n",
       "Dump of lib.rus.ec prepared for RUSSE workshop\n",
       "</br>\n",
       "</br>\n",
       "<code>wget http://panchenko.me/data/russe/librusec_fb2.plain.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://github.com/RossiyaSegodnya/ria_news_dataset\">Rossiya Segodnya</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ria_raw\"></a>\n",
       "<code><a href=\"#load_ria_raw\">load_ria_raw</a></code>\n",
       "</br>\n",
       "<a name=\"load_ria\"></a>\n",
       "<code><a href=\"#load_ria\">load_ria</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1&nbsp;003&nbsp;869\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "3.70 Gb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/RossiyaSegodnya/ria_news_dataset/raw/master/ria.json.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"http://study.mokoron.com/\">Mokoron Russian Twitter Corpus</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_mokoron\"></a>\n",
       "<code><a href=\"#load_mokoron\">load_mokoron</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>social</code>\n",
       "<code>sentiment</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "17&nbsp;633&nbsp;417\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1.86 Gb\n",
       "</td>\n",
       "<td>\n",
       "Russian Twitter sentiment markup\n",
       "</br>\n",
       "</br>\n",
       "Manually download https://www.dropbox.com/s/9egqjszeicki4ho/db.sql\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://dumps.wikimedia.org/\">Wikipedia</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_wiki\"></a>\n",
       "<code><a href=\"#load_wiki\">load_wiki</a></code>\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1&nbsp;541&nbsp;401\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "12.94 Gb\n",
       "</td>\n",
       "<td>\n",
       "Russian Wiki dump\n",
       "</br>\n",
       "</br>\n",
       "<code>wget https://dumps.wikimedia.org/ruwiki/latest/ruwiki-latest-pages-articles.xml.bz2</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://github.com/dialogue-evaluation/GramEval2020\">GramEval2020</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_gramru\"></a>\n",
       "<code><a href=\"#load_gramru\">load_gramru</a></code>\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "162&nbsp;372\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "30.04 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/dialogue-evaluation/GramEval2020/archive/master.zip</code>\n",
       "</br>\n",
       "<code>unzip master.zip</code>\n",
       "</br>\n",
       "<code>mv GramEval2020-master/dataTrain train</code>\n",
       "</br>\n",
       "<code>mv GramEval2020-master/dataOpenTest dev</code>\n",
       "</br>\n",
       "<code>rm -r master.zip GramEval2020-master</code>\n",
       "</br>\n",
       "<code>wget https://github.com/AlexeySorokin/GramEval2020/raw/master/data/GramEval_private_test.conllu</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"http://opencorpora.org/\">OpenCorpora</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_corpora\"></a>\n",
       "<code><a href=\"#load_corpora\">load_corpora</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "4&nbsp;030\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "20.21 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget http://opencorpora.org/files/export/annot/annot.opcorpora.xml.zip</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "RusVectores SimLex-965\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_simlex\"></a>\n",
       "<code><a href=\"#load_simlex\">load_simlex</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>emb</code>\n",
       "<code>sim</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://rusvectores.org/static/testsets/ru_simlex965_tagged.tsv</code>\n",
       "</br>\n",
       "<code>wget https://rusvectores.org/static/testsets/ru_simlex965.tsv</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://omnia-russica.github.io/\">Omnia Russica</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_omnia\"></a>\n",
       "<code><a href=\"#load_omnia\">load_omnia</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "<code>web</code>\n",
       "<code>fiction</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "489.62 Gb\n",
       "</td>\n",
       "<td>\n",
       "Taiga + Wiki + Araneum. Read \"Even larger Russian corpus\" https://events.spbu.ru/eventsContent/events/2019/corpora/corp_sborn.pdf\n",
       "</br>\n",
       "</br>\n",
       "Manually download http://bit.ly/2ZT4BY9\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://github.com/dialogue-evaluation/factRuEval-2016/\">factRuEval-2016</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_factru\"></a>\n",
       "<code><a href=\"#load_factru\">load_factru</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>ner</code>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "254\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "969.27 Kb\n",
       "</td>\n",
       "<td>\n",
       "Manual PER, LOC, ORG markup prepared for 2016 Dialog competition\n",
       "</br>\n",
       "</br>\n",
       "<code>wget https://github.com/dialogue-evaluation/factRuEval-2016/archive/master.zip</code>\n",
       "</br>\n",
       "<code>unzip master.zip</code>\n",
       "</br>\n",
       "<code>rm master.zip</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://www.researchgate.net/publication/262203599_Introducing_Baselines_for_Russian_Named_Entity_Recognition\">Gareev</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_gareev\"></a>\n",
       "<code><a href=\"#load_gareev\">load_gareev</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>ner</code>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "97\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "455.02 Kb\n",
       "</td>\n",
       "<td>\n",
       "Manual PER, ORG markup (no LOC)\n",
       "</br>\n",
       "</br>\n",
       "Email Rinat Gareev (gareev-rm@yandex.ru) ask for dataset\n",
       "</br>\n",
       "<code>tar -xvf rus-ner-news-corpus.iob.tar.gz</code>\n",
       "</br>\n",
       "<code>rm rus-ner-news-corpus.iob.tar.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"http://www.labinform.ru/pub/named_entities/\">Collection5</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ne5\"></a>\n",
       "<code><a href=\"#load_ne5\">load_ne5</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>ner</code>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1&nbsp;000\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "2.96 Mb\n",
       "</td>\n",
       "<td>\n",
       "News articles with manual PER, LOC, ORG markup\n",
       "</br>\n",
       "</br>\n",
       "<code>wget http://www.labinform.ru/pub/named_entities/collection5.zip</code>\n",
       "</br>\n",
       "<code>unzip collection5.zip</code>\n",
       "</br>\n",
       "<code>rm collection5.zip</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://www.aclweb.org/anthology/I17-1042\">WiNER</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_wikiner\"></a>\n",
       "<code><a href=\"#load_wikiner\">load_wikiner</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>ner</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "203&nbsp;287\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "36.15 Mb\n",
       "</td>\n",
       "<td>\n",
       "Sentences from Wiki auto annotated with PER, LOC, ORG tags\n",
       "</br>\n",
       "</br>\n",
       "<code>wget https://github.com/dice-group/FOX/raw/master/input/Wikiner/aij-wikiner-ru-wp3.bz2</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"http://bsnlp.cs.helsinki.fi/shared_task.html\">BSNLP-2019</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_bsnlp\"></a>\n",
       "<code><a href=\"#load_bsnlp\">load_bsnlp</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>ner</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "464\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1.16 Mb\n",
       "</td>\n",
       "<td>\n",
       "Markup prepared for 2019 BSNLP Shared Task\n",
       "</br>\n",
       "</br>\n",
       "<code>wget http://bsnlp.cs.helsinki.fi/TRAININGDATA_BSNLP_2019_shared_task.zip</code>\n",
       "</br>\n",
       "<code>wget http://bsnlp.cs.helsinki.fi/TESTDATA_BSNLP_2019_shared_task.zip</code>\n",
       "</br>\n",
       "<code>unzip TRAININGDATA_BSNLP_2019_shared_task.zip</code>\n",
       "</br>\n",
       "<code>unzip TESTDATA_BSNLP_2019_shared_task.zip -d test_pl_cs_ru_bg</code>\n",
       "</br>\n",
       "<code>rm TRAININGDATA_BSNLP_2019_shared_task.zip TESTDATA_BSNLP_2019_shared_task.zip</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"http://ai-center.botik.ru/Airec/index.php/ru/collections/28-persons-1000\">Persons-1000</a>\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_persons\"></a>\n",
       "<code><a href=\"#load_persons\">load_persons</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>ner</code>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1&nbsp;000\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "2.96 Mb\n",
       "</td>\n",
       "<td>\n",
       "Same as Collection5, only PER markup + normalized names\n",
       "</br>\n",
       "</br>\n",
       "<code>wget http://ai-center.botik.ru/Airec/ai-resources/Persons-1000.zip</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://tatianashavrina.github.io/taiga_site/\">Taiga</a>\n",
       "</td>\n",
       "<td colspan=\"5\">\n",
       "Large collection of Russian texts from various sources: news sites, magazines, literacy, social networks\n",
       "</br>\n",
       "</br>\n",
       "<code>wget https://linghub.ru/static/Taiga/retagged_taiga.tar.gz</code>\n",
       "</br>\n",
       "<code>tar -xzvf retagged_taiga.tar.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Arzamas\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_arzamas\"></a>\n",
       "<code><a href=\"#load_taiga_arzamas\">load_taiga_arzamas</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "311\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "4.50 Mb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Fontanka\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_fontanka\"></a>\n",
       "<code><a href=\"#load_taiga_fontanka\">load_taiga_fontanka</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "342&nbsp;683\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "786.23 Mb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Interfax\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_interfax\"></a>\n",
       "<code><a href=\"#load_taiga_interfax\">load_taiga_interfax</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "46&nbsp;429\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "77.55 Mb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "KP\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_kp\"></a>\n",
       "<code><a href=\"#load_taiga_kp\">load_taiga_kp</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "45&nbsp;503\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "61.79 Mb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Lenta\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_lenta\"></a>\n",
       "<code><a href=\"#load_taiga_lenta\">load_taiga_lenta</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "36&nbsp;446\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "95.15 Mb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Taiga/N+1\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_nplus1\"></a>\n",
       "<code><a href=\"#load_taiga_nplus1\">load_taiga_nplus1</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "7&nbsp;696\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "24.96 Mb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Magazines\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_magazines\"></a>\n",
       "<code><a href=\"#load_taiga_magazines\">load_taiga_magazines</a></code>\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "39&nbsp;890\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "2.19 Gb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Subtitles\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_subtitles\"></a>\n",
       "<code><a href=\"#load_taiga_subtitles\">load_taiga_subtitles</a></code>\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "19&nbsp;011\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "909.08 Mb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Social\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_social\"></a>\n",
       "<code><a href=\"#load_taiga_social\">load_taiga_social</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>social</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1&nbsp;876&nbsp;442\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "648.18 Mb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Proza\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_proza\"></a>\n",
       "<code><a href=\"#load_taiga_proza\">load_taiga_proza</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>fiction</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1&nbsp;732&nbsp;434\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "38.25 Gb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Stihi\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_taiga_stihi\"></a>\n",
       "<code><a href=\"#load_taiga_stihi\">load_taiga_stihi</a></code>\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "9&nbsp;157&nbsp;686\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "12.80 Gb\n",
       "</td>\n",
       "<td>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://github.com/buriy/russian-nlp-datasets/releases\">Russian NLP Datasets</a>\n",
       "</td>\n",
       "<td colspan=\"5\">\n",
       "Several Russian news datasets from webhose.io, lenta.ru and other news sites.\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "News\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_buriy_news\"></a>\n",
       "<code><a href=\"#load_buriy_news\">load_buriy_news</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "2&nbsp;154&nbsp;801\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "6.84 Gb\n",
       "</td>\n",
       "<td>\n",
       "Dump of top 40 news + 20 fashion news sites.\n",
       "</br>\n",
       "</br>\n",
       "<code>wget https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2014.tar.bz2</code>\n",
       "</br>\n",
       "<code>wget https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2015-part1.tar.bz2</code>\n",
       "</br>\n",
       "<code>wget https://github.com/buriy/russian-nlp-datasets/releases/download/r4/news-articles-2015-part2.tar.bz2</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Webhose\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_buriy_webhose\"></a>\n",
       "<code><a href=\"#load_buriy_webhose\">load_buriy_webhose</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "285&nbsp;965\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "859.32 Mb\n",
       "</td>\n",
       "<td>\n",
       "Dump from webhose.io, 300 sources for one month.\n",
       "</br>\n",
       "</br>\n",
       "<code>wget https://github.com/buriy/russian-nlp-datasets/releases/download/r4/webhose-2016.tar.bz2</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://github.com/ods-ai-ml4sg/proj_news_viz/releases/tag/data\">ODS #proj_news_viz</a>\n",
       "</td>\n",
       "<td colspan=\"5\">\n",
       "Several news sites scraped by members of #proj_news_viz ODS project.\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Interfax\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ods_interfax\"></a>\n",
       "<code><a href=\"#load_ods_interfax\">load_ods_interfax</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "543&nbsp;961\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1.22 Gb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/interfax.csv.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Gazeta\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ods_gazeta\"></a>\n",
       "<code><a href=\"#load_ods_gazeta\">load_ods_gazeta</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "865&nbsp;847\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1.63 Gb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/gazeta.csv.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Izvestia\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ods_izvestia\"></a>\n",
       "<code><a href=\"#load_ods_izvestia\">load_ods_izvestia</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "86&nbsp;601\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "307.19 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/iz.csv.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Meduza\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ods_meduza\"></a>\n",
       "<code><a href=\"#load_ods_meduza\">load_ods_meduza</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "71&nbsp;806\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "270.11 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/meduza.csv.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "RIA\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ods_ria\"></a>\n",
       "<code><a href=\"#load_ods_ria\">load_ods_ria</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "101&nbsp;543\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "233.88 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/ria.csv.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Russia Today\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ods_rt\"></a>\n",
       "<code><a href=\"#load_ods_rt\">load_ods_rt</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "106&nbsp;644\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "187.12 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/rt.csv.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "TASS\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ods_tass\"></a>\n",
       "<code><a href=\"#load_ods_tass\">load_ods_tass</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>news</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1&nbsp;135&nbsp;635\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "3.27 Gb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/tass-001.csv.gz</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://universaldependencies.org/\">Universal Dependencies</a>\n",
       "</td>\n",
       "<td colspan=\"5\">\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "GSD\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ud_gsd\"></a>\n",
       "<code><a href=\"#load_ud_gsd\">load_ud_gsd</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "<code>syntax</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "5&nbsp;030\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1.01 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-GSD/raw/master/ru_gsd-ud-dev.conllu</code>\n",
       "</br>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-GSD/raw/master/ru_gsd-ud-test.conllu</code>\n",
       "</br>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-GSD/raw/master/ru_gsd-ud-train.conllu</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Taiga\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ud_taiga\"></a>\n",
       "<code><a href=\"#load_ud_taiga\">load_ud_taiga</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "<code>syntax</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "3&nbsp;264\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "353.80 Kb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-Taiga/raw/master/ru_taiga-ud-dev.conllu</code>\n",
       "</br>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-Taiga/raw/master/ru_taiga-ud-test.conllu</code>\n",
       "</br>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-Taiga/raw/master/ru_taiga-ud-train.conllu</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "PUD\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ud_pud\"></a>\n",
       "<code><a href=\"#load_ud_pud\">load_ud_pud</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "<code>syntax</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "1&nbsp;000\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "207.78 Kb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-PUD/raw/master/ru_pud-ud-test.conllu</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "SynTagRus\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_ud_syntag\"></a>\n",
       "<code><a href=\"#load_ud_syntag\">load_ud_syntag</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "<code>syntax</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "61&nbsp;889\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "11.33 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/master/ru_syntagrus-ud-dev.conllu</code>\n",
       "</br>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/master/ru_syntagrus-ud-test.conllu</code>\n",
       "</br>\n",
       "<code>wget https://github.com/UniversalDependencies/UD_Russian-SynTagRus/raw/master/ru_syntagrus-ud-train.conllu</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://github.com/dialogue-evaluation/morphoRuEval-2017\">morphoRuEval-2017</a>\n",
       "</td>\n",
       "<td colspan=\"5\">\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "General Internet-Corpus\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_morphoru_gicrya\"></a>\n",
       "<code><a href=\"#load_morphoru_gicrya\">load_morphoru_gicrya</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "83&nbsp;148\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "10.58 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/GIKRYA_texts_new.zip</code>\n",
       "</br>\n",
       "<code>unzip GIKRYA_texts_new.zip</code>\n",
       "</br>\n",
       "<code>rm GIKRYA_texts_new.zip</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Russian National Corpus\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_morphoru_rnc\"></a>\n",
       "<code><a href=\"#load_morphoru_rnc\">load_morphoru_rnc</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "98&nbsp;892\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "12.71 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/RNC_texts.rar</code>\n",
       "</br>\n",
       "<code>unrar x RNC_texts.rar</code>\n",
       "</br>\n",
       "<code>rm RNC_texts.rar</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "OpenCorpora\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_morphoru_corpora\"></a>\n",
       "<code><a href=\"#load_morphoru_corpora\">load_morphoru_corpora</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>morph</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "38&nbsp;510\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "4.80 Mb\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/OpenCorpora_Texts.rar</code>\n",
       "</br>\n",
       "<code>unrar x OpenCorpora_Texts.rar</code>\n",
       "</br>\n",
       "<code>rm OpenCorpora_Texts.rar</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://russe.nlpub.org/downloads/\">RUSSE Russian Semantic Relatedness</a>\n",
       "</td>\n",
       "<td colspan=\"5\">\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "HJ: Human Judgements of Word Pairs\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_russe_hj\"></a>\n",
       "<code><a href=\"#load_russe_hj\">load_russe_hj</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>emb</code>\n",
       "<code>sim</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/nlpub/russe-evaluation/raw/master/russe/evaluation/hj.csv</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "RT: Synonyms and Hypernyms from the Thesaurus RuThes\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_russe_rt\"></a>\n",
       "<code><a href=\"#load_russe_rt\">load_russe_rt</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>emb</code>\n",
       "<code>sim</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://raw.githubusercontent.com/nlpub/russe-evaluation/master/russe/evaluation/rt.csv</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "AE: Cognitive Associations from the Sociation.org Experiment\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_russe_ae\"></a>\n",
       "<code><a href=\"#load_russe_ae\">load_russe_ae</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>emb</code>\n",
       "<code>sim</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://github.com/nlpub/russe-evaluation/raw/master/russe/evaluation/ae-train.csv</code>\n",
       "</br>\n",
       "<code>wget https://github.com/nlpub/russe-evaluation/raw/master/russe/evaluation/ae-test.csv</code>\n",
       "</br>\n",
       "<code>wget https://raw.githubusercontent.com/nlpub/russe-evaluation/master/russe/evaluation/ae2.csv</code>\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "<a href=\"https://toloka.yandex.ru/datasets/\">Toloka Datasets</a>\n",
       "</td>\n",
       "<td colspan=\"5\">\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "Lexical Relations from the Wisdom of the Crowd (LRWC)\n",
       "</td>\n",
       "<td>\n",
       "<a name=\"load_toloka_lrwc\"></a>\n",
       "<code><a href=\"#load_toloka_lrwc\">load_toloka_lrwc</a></code>\n",
       "</td>\n",
       "<td>\n",
       "<code>emb</code>\n",
       "<code>sim</code>\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td align=\"right\">\n",
       "</td>\n",
       "<td>\n",
       "<code>wget https://tlk.s3.yandex.net/dataset/LRWC.zip</code>\n",
       "</br>\n",
       "<code>unzip LRWC.zip</code>\n",
       "</br>\n",
       "<code>rm LRWC.zip</code>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from corus.sources.meta import METAS\n",
    "from corus.readme import format_metas, show_html, patch_readme\n",
    "\n",
    "html = format_metas(METAS)\n",
    "show_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-13 16:57:45--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.3, 198.51.44.8, 198.51.45.8, ...\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210213T135745Z&X-Amz-Expires=300&X-Amz-Signature=5e06f9e21f4f9a5ce780cc6903cc9a78aa2ab87abcad2f3e9441111d6d710736&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-02-13 16:57:45--  https://github-releases.githubusercontent.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210213T135745Z&X-Amz-Expires=300&X-Amz-Signature=5e06f9e21f4f9a5ce780cc6903cc9a78aa2ab87abcad2f3e9441111d6d710736&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.110.154, 185.199.111.154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 527373240 (503M) [application/octet-stream]\n",
      "Saving to: ‘lenta-ru-news.csv.gz’\n",
      "\n",
      "lenta-ru-news.csv.g 100%[===================>] 502.94M   503KB/s    in 21m 38s \n",
      "\n",
      "2021-02-13 17:19:23 (397 KB/s) - ‘lenta-ru-news.csv.gz’ saved [527373240/527373240]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим три функции:\n",
    "\n",
    "- `text_prepare` - производит предобработку предложения\n",
    "- `get_grams_from_text` - получает корпус слов и биграммы\n",
    "- `predict` - предсказывает по корпусу слов и словарю биграмм следующее слово предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text, language='russian', delete_stop_words=False):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified string\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # 1. Перевести символы в нижний регистр\n",
    "    text = text.lower() #your code\n",
    "    \n",
    "    # 2.1 Заменить символы пунктуации на пробелы\n",
    "    text = re.sub(r'[{}]'.format(string.punctuation), ' ', text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 2.2 Удалить \"плохие\" символы\n",
    "    text = re.sub('[^A-Za-z0-9]' if language == 'english' else '[^А-яа-я]', ' ', text)\n",
    "\n",
    "    \n",
    "    # 3. Применить WordNetLemmatizer\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    \n",
    "    # 4. Удалить стопслова.\n",
    "    if delete_stop_words:\n",
    "        stopWords = set(stopwords.words(language))\n",
    "        for stopWord in stopWords:\n",
    "            text = re.sub(r'\\b{}\\b'.format(stopWord), '', text)\n",
    "        \n",
    "    # 5. Удаляю пробелы у получая просто строку слов через пробел\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def get_grams_from_text(path='lenta-ru-news.csv.gz', \n",
    "                        n=2, \n",
    "                        amount_of_sentense=1000, \n",
    "                        verbose=True, \n",
    "                        show_how_much=1000, **kwargs):\n",
    "    records = load_lenta(path)\n",
    "    grams, count = {}, 1\n",
    "    flatten = lambda l: [' '.join(item) for sublist in l for item in sublist]\n",
    "    try:\n",
    "        while True and count != amount_of_sentense:\n",
    "            item = next(records).text\n",
    "            if verbose:\n",
    "                print(f'Sentence {count}') if count % show_how_much == 0 else 'pass'\n",
    "            \n",
    "            for i in np.arange(1, n+1):\n",
    "                if i not in list(grams.keys()):\n",
    "                    grams[i] = Counter()\n",
    "                ngram = [list(ngrams(text_prepare(sentense, **kwargs).lower().split(), n=i)) for sentense in nltk.sent_tokenize(item)]\n",
    "                grams[i] += Counter(flatten(ngram))\n",
    "            count +=1\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    finally:\n",
    "        del records\n",
    "    return grams\n",
    "\n",
    "\n",
    "def predict(corpus, sentence, n=3):\n",
    "    sen = text_prepare(sentence)\n",
    "    cor = corpus.copy()\n",
    "    rev = sen.split()[::-1]\n",
    "    s = sum(list(cor[2].values()))\n",
    "    s1 = sum(list(cor[1].values()))\n",
    "    d = {}\n",
    "    for key, value in list(cor[1].items()):\n",
    "        a = []\n",
    "        for i in np.arange(1, n+1):\n",
    "            v = cor[2][f'{rev[i-1]} {key}']\n",
    "            a.append(np.log(v / s) if v!=0 else np.log(0.000001))\n",
    "        d[key] = sum([np.log(value / s1)] + a)    \n",
    "    return sentence + ' ' + max(d.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим корпус слов из русского набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 2000\n",
      "Sentence 4000\n",
      "Sentence 6000\n"
     ]
    }
   ],
   "source": [
    "g = get_grams_from_text(n=2, \n",
    "                        amount_of_sentense=8000, \n",
    "                        show_how_much=2000, \n",
    "                        delete_stop_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 2000\n",
      "Sentence 4000\n",
      "Sentence 6000\n"
     ]
    }
   ],
   "source": [
    "g2 = get_grams_from_text(n=2, \n",
    "                         amount_of_sentense=8000, \n",
    "                         show_how_much=2000, \n",
    "                         delete_stop_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажем с помощью языковых моделей следующее слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'невозможно предсказать слово правильно в'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predict(corpus=g, sentence='невозможно предсказать слово правильно', n=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'невозможно предсказать слово правильно года'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predict(corpus=g2, sentence='невозможно предсказать слово правильно', n=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'смотри выше меня этот человек который'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = predict(corpus=g2, sentence='смотри выше меня этот человек', n=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "смотри\n",
      "смотри в\n",
      "смотри в в\n",
      "смотри в в в\n",
      "смотри в в в в\n",
      "смотри в в в в в\n",
      "смотри в в в в в в\n"
     ]
    }
   ],
   "source": [
    "word = 'смотри'\n",
    "\n",
    "for i in range(6):\n",
    "    print(word, end='\\n')\n",
    "    word = predict(corpus=g, sentence=word, n=1)\n",
    "    \n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "смотри\n",
      "смотри это\n",
      "смотри это время\n",
      "смотри это время года\n",
      "смотри это время года россии\n",
      "смотри это время года россии сша\n",
      "смотри это время года россии сша также\n",
      "смотри это время года россии сша также отметил\n",
      "смотри это время года россии сша также отметил это\n"
     ]
    }
   ],
   "source": [
    "word = 'смотри'\n",
    "\n",
    "for i in range(8):\n",
    "    print(word, end='\\n')\n",
    "    word = predict(corpus=g2, sentence=word, n=1)\n",
    "    \n",
    "print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
