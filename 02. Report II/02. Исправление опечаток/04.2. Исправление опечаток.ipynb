{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unlikely-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_text import get_grams_from_text\n",
    "from corus.sources.meta import METAS\n",
    "from corus.readme import format_metas, show_html, patch_readme\n",
    "\n",
    "html = format_metas(METAS)\n",
    "#show_html(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-roots",
   "metadata": {},
   "source": [
    "```bash\n",
    "!wget -P ~/IHaskell/word_data/ https://github.com/dialogue-evaluation/GramEval2020/archive/master.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "foreign-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 5000\n",
      "Sentence 10000\n",
      "Sentence 15000\n"
     ]
    }
   ],
   "source": [
    "g = get_grams_from_text(path='../../../word_data/lenta-ru-news.csv.gz',\n",
    "                        n=1, \n",
    "                        amount_of_sentense=20000, \n",
    "                        show_how_much=5000, \n",
    "                        delete_stop_words=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-watch",
   "metadata": {},
   "source": [
    "## Спеллчекер Питера Норвига"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "comprehensive-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = g[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "electrical-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "preceding-description",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'произносить'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('произность')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "driving-representative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'примерная'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('примерчная')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-soccer",
   "metadata": {},
   "source": [
    "**Links**:\n",
    "\n",
    "- [Текст с ошибками](https://yandex.ru/search/?text=Efficient%20Dependency%20Parsing%20In%20Case%20Of%20Ungrammatical%20Sentences&clid=2411726&lr=2)\n",
    "- [Распознавание текста с ошибками](https://ru.stackoverflow.com/questions/859694/%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5-%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0-%D1%81-%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B0%D0%BC%D0%B8)\n",
    "- [Опечатки с учетом контекста](https://habr.com/ru/post/346618/)\n",
    "- [Spell-Corrector](http://norvig.com/spell-correct.html)\n",
    "- [Project JetBrains](https://internship.jetbrains.com/projects/848/)\n",
    "- [Supar](https://github.com/yzhangcs/parser)\n",
    "- [Error-repair Dependency](https://www.aclweb.org/anthology/P17-2030.pdf)\n",
    "- [Parser](https://github.com/HHashemi?tab=repositories)\n",
    "- [Dependency Parser](https://medium.com/data-science-in-your-pocket/dependency-parsing-associated-algorithms-in-nlp-96d65dd95d3e)\n",
    "- [Dependency NLP Parser](http://nlpprogress.com/english/dependency_parsing.html)\n",
    "- [Error-repair Dependency Paper](https://www.researchgate.net/publication/318741850_Error-repair_Dependency_Parsing_for_Ungrammatical_Texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma_paper",
   "language": "python",
   "name": "diploma_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
